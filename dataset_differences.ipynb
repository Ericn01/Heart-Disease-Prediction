{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d9d195",
   "metadata": {},
   "source": [
    "# Dataset (Population) Differences\n",
    "\n",
    "We're now going to investigate the population differences between datasets. This is going to be done over a few dimensions:\n",
    "\n",
    "1. **Dataset Size & Completeness**: How many observations each dataset has and the percent of rows that do not contain any missing values.\n",
    "2. **Feature Level Missingness**: Compare which features are missing in each dataset and in what quantities.\n",
    "3. **CVD Class Distribution**: Test whether disease severity differs across population using chi-square (*super important and useful to know*).\n",
    "4. **Numeric Features**: Compare age, blood pressure, cholesterol, etc. across datasets using Kruskal-Wallis tests (non-parametric alternative to ANOVA) \n",
    "5. **Categorical Features**: Analyzes sex, chest pain types, etc. with chi-square tests\n",
    "6. **Correlation Structure**: Observe if feature relationships differ by population\n",
    "\n",
    "This analysis helps with building a multi-class CVD prediction model for a few reasons, mainly: \n",
    "\n",
    "- Population differences may require different feature weights.\n",
    "- Different CVD prevalence means you'll need stratified sampling.\n",
    "- Common risk factors to the development of cardiovascular disease can be validated by looking at which features are consistently associated with CVD Class across all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30860ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_datasets import dfs\n",
    "\n",
    "overview_stats = []\n",
    "for name, _df in zip(dataset_names, dfs):\n",
    "    analyzable_df = _df.replace('?', np.nan) # Important step as they won't be count as missing if this isn't done \n",
    "\n",
    "    total_cells = analyzable_df.shape[0] * analyzable_df.shape[1]\n",
    "    missing_cells = analyzable_df.isnull().sum().sum()\n",
    "    complete_cases = (~analyzable_df.isnull().any(axis=1)).sum()\n",
    "    \n",
    "    overview_stats.append({\n",
    "        'Dataset': name,\n",
    "        'N_Observations': analyzable_df.shape[0],\n",
    "        'N_Features': analyzable_df.shape[1],\n",
    "        'Complete_Cases': complete_cases,\n",
    "        'Complete_Cases_%': (complete_cases / analyzable_df.shape[0] * 100),\n",
    "        'Missing_Cells': missing_cells,\n",
    "        'Missing_%': (missing_cells / total_cells * 100)\n",
    "    })\n",
    "\n",
    "overview_df = pd.DataFrame(overview_stats)\n",
    "\n",
    "overview_df.round()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
